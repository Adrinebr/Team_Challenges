{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion: eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(target, predictions, problem_type, metrics):\n",
    "    \"\"\"\n",
    "    Evalúa un modelo de Machine Learning utilizando diferentes métricas especificadas por el usuario.\n",
    "\n",
    "    Argumentos:\n",
    "    target (tipo array): Valores reales del target.\n",
    "    predictions (tipo array): Valores predichos por el modelo.\n",
    "    problem_type (str): Tipo de problema, puede ser 'regression' o 'classification'.\n",
    "    metrics (list): Lista de métricas a calcular y mostrar. Las métricas disponibles dependen del tipo de problema.\n",
    "                     Para problemas de regresión: 'RMSE', 'MAE', 'MAPE', 'GRAPH'.\n",
    "                     Para problemas de clasificación: 'ACCURACY', 'PRECISION', 'RECALL', 'CLASS_REPORT', 'MATRIX',\n",
    "                                                        'MATRIX_RECALL', 'MATRIX_PRED', 'PRECISION_X', 'RECALL_X'.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Una tupla con los valores de las métricas solicitadas en el orden especificado en la lista de métricas.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    #REGRESION\n",
    "    if problem_type == 'regression':\n",
    "        for metric in metrics:\n",
    "            #Empezamos con RMSE\n",
    "            if metric == 'RMSE':\n",
    "                rmse = np.sqrt(mean_squared_error(target, predictions))\n",
    "                print(f\"RMSE: {rmse}\")\n",
    "                results.append(rmse)\n",
    "\n",
    "            #Seguimos con MAE\n",
    "            elif metric == 'MAE':\n",
    "                mae = mean_absolute_error(target, predictions)\n",
    "                print(f\"MAE: {mae}\")\n",
    "                results.append(mae)\n",
    "\n",
    "            #Seguimos con MAPE\n",
    "            elif metric == 'MAPE':\n",
    "                try:\n",
    "                    mape = np.mean(np.abs((target - predictions) / target)) * 100\n",
    "                    print(f\"MAPE: {mape}\")\n",
    "                    results.append(mape)\n",
    "                #Imprimir ValueError\n",
    "                except ZeroDivisionError:\n",
    "                    raise ValueError(\"No se puede calcular MAPE cuando hay valores de target iguales a cero.\")\n",
    "           \n",
    "            #Seguimos con GRAPH\n",
    "            elif metric == 'GRAPH':\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.scatter(target, predictions)\n",
    "                plt.xlabel('Real')\n",
    "                plt.ylabel('Predicción')\n",
    "                plt.title('Gráfico de dispersión de Predicciones vs. Real')\n",
    "                plt.show()\n",
    "    \n",
    "    #CLASIFICACION\n",
    "    elif problem_type == 'classification':\n",
    "        for metric in metrics:\n",
    "            \n",
    "            #Empezamos con ACCURACY\n",
    "            if metric == 'ACCURACY':\n",
    "                accuracy = accuracy_score(target, predictions)\n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                results.append(accuracy)\n",
    "\n",
    "            #Seguimos con PRECISION\n",
    "            elif metric == 'PRECISION':\n",
    "                precision = precision_score(target, predictions, average='macro')\n",
    "                print(f\"Precision: {precision}\")\n",
    "                results.append(precision)\n",
    "\n",
    "            #Seguimos con RECALL\n",
    "            elif metric == 'RECALL':\n",
    "                recall = recall_score(target, predictions, average='macro')\n",
    "                print(f\"Recall: {recall}\")\n",
    "                results.append(recall)\n",
    "\n",
    "            # Seguimos con CLASS_REPORT\n",
    "            elif metric == 'CLASS_REPORT':\n",
    "                print(\"Classification Report:\")\n",
    "                print(classification_report(target, predictions))\n",
    "\n",
    "            # Seguimos con NEO, Perdon, con MATRIX (#Dadjoke)\n",
    "            elif metric == 'MATRIX':\n",
    "                print(\"Confusion Matrix (Absolute Values):\")\n",
    "                print(confusion_matrix(target, predictions))\n",
    "\n",
    "            # Seguimos con MATRIX_RECALL\n",
    "            elif metric == 'MATRIX_RECALL':\n",
    "                disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(target, predictions))\n",
    "                disp.plot(normalize='true')\n",
    "                plt.title('Confusion Matrix (Normalized by Recall)')\n",
    "                plt.show()\n",
    "\n",
    "             # Seguimos con MATRIX_PRED\n",
    "            elif metric == 'MATRIX_PRED':\n",
    "                disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(target, predictions))\n",
    "                disp.plot(normalize='pred')\n",
    "                plt.title('Confusion Matrix (Normalized by Prediction)')\n",
    "                plt.show()\n",
    "\n",
    "            elif 'PRECISION_' in metric:\n",
    "                class_label = metric.split('_')[-1] # Obtener la etiqueta de clase de la métrica\n",
    "                try:\n",
    "                    precision_class = precision_score(target, predictions, labels=[class_label])\n",
    "                    print(f\"Precision for class {class_label}: {precision_class}\")\n",
    "                    results.append(precision_class)\n",
    "                except ValueError:\n",
    "                    raise ValueError(f\"La clase {class_label} no está presente en las predicciones.\")\n",
    "            elif 'RECALL_' in metric:\n",
    "                class_label = metric.split('_')[-1]\n",
    "                try:\n",
    "                    recall_class = recall_score(target, predictions, labels=[class_label])\n",
    "                    print(f\"Recall for class {class_label}: {recall_class}\")\n",
    "                    results.append(recall_class)\n",
    "                except ValueError:\n",
    "                    raise ValueError(f\"La clase {class_label} no está presente en las predicciones.\")\n",
    "    else:\n",
    "        raise ValueError(\"El tipo de problema debe ser 'regression' o 'classification'.\")\n",
    "\n",
    "    return tuple(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Añado una versión alternativa, donde se muestran todas las métricas posibles para cada tipo de problema de predicción*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_all_metrics(target, predictions, problem_type):\n",
    "    \"\"\"\n",
    "    Evalúa un modelo de Machine Learning utilizando todas las métricas disponibles para el tipo de problema especificado.\n",
    "\n",
    "    Argumentos:\n",
    "    target (tipo array): Valores reales del target.\n",
    "    predictions (tipo array): Valores predichos por el modelo.\n",
    "    problem_type (str): Tipo de problema, puede ser 'regression' o 'classification'.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Una tupla con los valores de las métricas calculadas en el orden especificado.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    if problem_type == 'regression':\n",
    "        rmse = np.sqrt(mean_squared_error(target, predictions))\n",
    "        mae = mean_absolute_error(target, predictions)\n",
    "        try:\n",
    "            mape = np.mean(np.abs((target - predictions) / target)) * 100\n",
    "        except ZeroDivisionError:\n",
    "            raise ValueError(\"No se puede calcular MAPE cuando hay valores de target iguales a cero.\")\n",
    "        \n",
    "        print(f\"RMSE: {rmse}\")\n",
    "        print(f\"MAE: {mae}\")\n",
    "        print(f\"MAPE: {mape}\")\n",
    "        results.extend([rmse, mae, mape])\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(target, predictions)\n",
    "        plt.xlabel('Real')\n",
    "        plt.ylabel('Predicción')\n",
    "        plt.title('Gráfico de dispersión de Predicciones vs. Real')\n",
    "        plt.show()\n",
    "\n",
    "    elif problem_type == 'classification':\n",
    "        accuracy = accuracy_score(target, predictions)\n",
    "        precision = precision_score(target, predictions, average='macro')\n",
    "        recall = recall_score(target, predictions, average='macro')\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        results.extend([accuracy, precision, recall])\n",
    "        \n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(target, predictions))\n",
    "        \n",
    "        print(\"Confusion Matrix (Absolute Values):\")\n",
    "        print(confusion_matrix(target, predictions))\n",
    "        \n",
    "        disp_recall = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(target, predictions))\n",
    "        disp_recall.plot(normalize='true')\n",
    "        plt.title('Confusion Matrix (Normalized by Recall)')\n",
    "        plt.show()\n",
    "        \n",
    "        disp_pred = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(target, predictions))\n",
    "        disp_pred.plot(normalize='pred')\n",
    "        plt.title('Confusion Matrix (Normalized by Prediction)')\n",
    "        plt.show()\n",
    "        \n",
    "        unique_labels = np.unique(target)\n",
    "        for label in unique_labels:\n",
    "            precision_class = precision_score(target, predictions, labels=[label])\n",
    "            recall_class = recall_score(target, predictions, labels=[label])\n",
    "            print(f\"Precision for class {label}: {precision_class}\")\n",
    "            print(f\"Recall for class {label}: {recall_class}\")\n",
    "            results.extend([precision_class, recall_class])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"El tipo de problema debe ser 'regression' o 'classification'.\")\n",
    "\n",
    "    return tuple(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion: get_features_num_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_num_classification(dataframe, target_col, pvalue=0.05):\n",
    "    \"\"\"\n",
    "    Devuelve una lista con las columnas numéricas del dataframe cuyo ANOVA con la columna designada por \"target_col\"\n",
    "    supere el test de hipótesis con significación mayor o igual a 1-pvalue.\n",
    "\n",
    "    Argumentos:\n",
    "    dataframe (pd.DataFrame): DataFrame que contiene los datos.\n",
    "    target_col (str): Nombre de la columna que debería ser el target de un modelo de clasificación.\n",
    "    pvalue (float): Valor de significación para el test de hipótesis. Por defecto es 0.05.\n",
    "\n",
    "    Returns:\n",
    "    list: Lista de columnas numéricas cuyo ANOVA supera el test de hipótesis.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Comprobación de que el dataframe no esté vacío\n",
    "    if dataframe.empty:\n",
    "        print(\"Error: El dataframe está vacío.\")\n",
    "        return None\n",
    "    \n",
    "    # Comprobación de que el target_col exista en el dataframe\n",
    "    if target_col not in dataframe.columns:\n",
    "        print(f\"Error: La columna {target_col} no existe en el dataframe.\")\n",
    "        return None\n",
    "    \n",
    "    # Comprobación de que target_col sea categórica\n",
    "    if not pd.api.types.is_categorical_dtype(dataframe[target_col]):\n",
    "        print(f\"Error: La columna {target_col} no es categórica.\")\n",
    "        return None\n",
    "    \n",
    "    # Filtrar columnas numéricas\n",
    "    numeric_columns = dataframe.select_dtypes(include=['float64', 'int64']).columns\n",
    "    \n",
    "    # Comprobación de que hay al menos una columna numérica\n",
    "    if not numeric_columns.any():\n",
    "        print(\"Error: No hay columnas numéricas en el dataframe.\")\n",
    "        return None\n",
    "    \n",
    "    # Comprobación de que el pvalue sea un float válido entre 0 y 1\n",
    "    if not isinstance(pvalue, float) or pvalue < 0 or pvalue > 1:\n",
    "        print(\"Error: El valor de pvalue debe ser un float válido entre 0 y 1.\")\n",
    "        return None\n",
    "    \n",
    "    # Comprobación de que el dataframe tenga al menos dos categorías en target_col\n",
    "    if len(dataframe[target_col].unique()) < 2:\n",
    "        print(f\"Error: La columna {target_col} tiene menos de dos categorías únicas.\")\n",
    "        return None\n",
    "    \n",
    "    # Realizar ANOVA para cada columna numérica\n",
    "    selected_features = []\n",
    "    for col in numeric_columns:\n",
    "        _, pval = f_oneway(*[dataframe[col][dataframe[target_col] == category] for category in dataframe[target_col].unique()])\n",
    "        if pval >= 1 - pvalue:\n",
    "            selected_features.append(col)\n",
    "    \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion: plot_features_num_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_num_classification(dataframe, target_col=\"\", columns=[], pvalue=0.05):\n",
    "    \"\"\"\n",
    "    Genera un pairplot del dataframe considerando la columna designada por \"target_col\" y aquellas incluidas en \"columns\"\n",
    "    que cumplan el test de ANOVA para el nivel 1-pvalue de significación estadística.\n",
    "\n",
    "    Argumentos:\n",
    "    dataframe (pd.DataFrame): DataFrame que contiene los datos.\n",
    "    target_col (str): Nombre de la columna que se usará como variable categórica en el pairplot. Por defecto es \"\".\n",
    "    columns (list): Lista de columnas numéricas a considerar para el pairplot. Por defecto es la lista vacía.\n",
    "    pvalue (float): Valor de significación para el test de ANOVA. Por defecto es 0.05.\n",
    "\n",
    "    Returns:\n",
    "    list: Lista de columnas numéricas que cumplen con las condiciones de ANOVA.\n",
    "    \"\"\"\n",
    "\n",
    "    # Comprobación de que el dataframe no esté vacío\n",
    "    if dataframe.empty:\n",
    "        print(\"Error: El dataframe está vacío.\")\n",
    "        return None\n",
    "\n",
    "    # Comprobación de que target_col exista en el dataframe\n",
    "    if target_col not in dataframe.columns:\n",
    "        print(f\"Error: La columna {target_col} no existe en el dataframe.\")\n",
    "        return None\n",
    "\n",
    "    # Comprobación de que target_col sea categórica\n",
    "    if not pd.api.types.is_categorical_dtype(dataframe[target_col]):\n",
    "        print(f\"Error: La columna {target_col} no es categórica.\")\n",
    "        return None\n",
    "\n",
    "    # Filtrar columnas numéricas si columns está vacía\n",
    "    if not columns:\n",
    "        columns = dataframe.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "    # Comprobación de que hay al menos una columna numérica\n",
    "    if not columns:\n",
    "        print(\"Error: No hay columnas numéricas en el dataframe.\")\n",
    "        return None\n",
    "\n",
    "    # Comprobación de que el pvalue sea un float válido entre 0 y 1\n",
    "    if not isinstance(pvalue, float) or pvalue < 0 or pvalue > 1:\n",
    "        print(\"Error: El valor de pvalue debe ser un float válido entre 0 y 1.\")\n",
    "        return None\n",
    "\n",
    "    # Comprobación de que el dataframe tenga al menos dos categorías en target_col\n",
    "    if len(dataframe[target_col].unique()) < 2:\n",
    "        print(f\"Error: La columna {target_col} tiene menos de dos categorías únicas.\")\n",
    "        return None\n",
    "\n",
    "    # Seleccionar solo las columnas que cumplen el test de ANOVA\n",
    "    selected_columns = []\n",
    "    for col in columns:\n",
    "        _, pval = f_oneway(*[dataframe[col][dataframe[target_col] == category] for category in dataframe[target_col].unique()])\n",
    "        if pval >= 1 - pvalue:\n",
    "            selected_columns.append(col)\n",
    "\n",
    "    # Comprobación de que hay al menos una columna seleccionada\n",
    "    if not selected_columns:\n",
    "        print(\"Error: No hay columnas que cumplan con las condiciones de ANOVA.\")\n",
    "        return None\n",
    "\n",
    "    # Dividir el pairplot si el número de valores únicos en target_col es mayor que 5\n",
    "    if len(dataframe[target_col].unique()) > 5:\n",
    "        unique_targets = dataframe[target_col].unique()\n",
    "        for i in range(0, len(unique_targets), 5):\n",
    "            plot_data = dataframe[dataframe[target_col].isin(unique_targets[i:i+5])]\n",
    "            plot = sns.pairplot(plot_data, hue=target_col, vars=[target_col] + selected_columns)\n",
    "            plt.show()\n",
    "    else:\n",
    "        # Comprobar si hay que dividir el pairplot si el número de columnas seleccionadas es grande\n",
    "        if len(selected_columns) > 5:\n",
    "            # Dividir las columnas en grupos de máximo 5\n",
    "            column_combinations = [selected_columns[i:i+4] for i in range(0, len(selected_columns), 4)]\n",
    "            for cols in column_combinations:\n",
    "                plot = sns.pairplot(dataframe, hue=target_col, vars=[target_col] + cols)\n",
    "                plt.show()\n",
    "        else:\n",
    "            # Generar pairplot\n",
    "            plot = sns.pairplot(dataframe, hue=target_col, vars=[target_col] + selected_columns)\n",
    "            plt.show()\n",
    "\n",
    "    return selected_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion: get_features_cat_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_cat_classification(dataframe, target_col, normalize=False, mi_threshold=0):\n",
    "    \"\"\"\n",
    "    Devuelve una lista con las columnas categóricas del dataframe cuyo valor de mutual information con 'target_col'\n",
    "    iguale o supere el valor de \"mi_threshold\".\n",
    "\n",
    "    Argumentos:\n",
    "    dataframe (pd.DataFrame): DataFrame que contiene los datos.\n",
    "    target_col (str): Nombre de la columna que debería ser el target de un modelo de clasificación.\n",
    "    normalize (bool): Indica si se debe normalizar el valor de mutual information. Por defecto es False.\n",
    "    mi_threshold (float): Umbral de mutual information. Por defecto es 0.\n",
    "\n",
    "    Returns:\n",
    "    list: Lista de columnas categóricas que cumplen con las condiciones de mutual information.\n",
    "    \"\"\"\n",
    "\n",
    "    # Comprobación de que el dataframe no esté vacío\n",
    "    if dataframe.empty:\n",
    "        print(\"Error: El dataframe está vacío.\")\n",
    "        return None\n",
    "    \n",
    "    # Comprobación de que target_col exista en el dataframe\n",
    "    if target_col not in dataframe.columns:\n",
    "        print(f\"Error: La columna {target_col} no existe en el dataframe.\")\n",
    "        return None\n",
    "\n",
    "    # Comprobación de que target_col sea categórica\n",
    "    if not pd.api.types.is_categorical_dtype(dataframe[target_col]):\n",
    "        print(f\"Error: La columna {target_col} no es categórica.\")\n",
    "        return None\n",
    "    \n",
    "    # Comprobación de que normalize sea un booleano\n",
    "    if not isinstance(normalize, bool):\n",
    "        print(\"Error: El valor de normalize debe ser un booleano.\")\n",
    "        return None\n",
    "    \n",
    "    # Comprobación de que mi_threshold sea un float válido entre 0 y 1 si normalize es True\n",
    "    if normalize and (not isinstance(mi_threshold, float) or mi_threshold < 0 or mi_threshold > 1):\n",
    "        print(\"Error: El valor de mi_threshold debe ser un float válido entre 0 y 1 cuando normalize es True.\")\n",
    "        return None\n",
    "\n",
    "    # Filtrar columnas categóricas\n",
    "    categorical_columns = dataframe.select_dtypes(include=['category']).columns\n",
    "    \n",
    "    # Comprobación de que hay al menos una columna categórica\n",
    "    if not categorical_columns.any():\n",
    "        print(\"Error: No hay columnas categóricas en el dataframe.\")\n",
    "        return None\n",
    "\n",
    "    # Calcular mutual information\n",
    "    mi_values = mutual_info_classif(dataframe[categorical_columns], dataframe[target_col], discrete_features=True, random_state=42)\n",
    "    \n",
    "    # Normalizar si es necesario\n",
    "    if normalize:\n",
    "        total_mi = sum(mi_values)\n",
    "        mi_values = [mi / total_mi for mi in mi_values]\n",
    "    \n",
    "    # Seleccionar las columnas que cumplen con el threshold\n",
    "    selected_columns = [categorical_columns[i] for i, mi in enumerate(mi_values) if mi >= mi_threshold]\n",
    "\n",
    "    return selected_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion: plot_features_cat_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_cat_classification(dataframe, target_col=\"\", columns=[], mi_threshold=0.0, normalize=False):\n",
    "    \"\"\"\n",
    "    Pinta la distribución de etiquetas de cada valor respecto a los valores de la columna \"target_col\"\n",
    "    para las columnas categóricas del dataframe cuyo valor de mutual information respecto de target_col\n",
    "    supere el umbral dado en \"mi_threshold\".\n",
    "\n",
    "    Argumentos:\n",
    "    dataframe (pd.DataFrame): DataFrame que contiene los datos.\n",
    "    target_col (str): Nombre de la columna que debería ser el target de un modelo de clasificación.\n",
    "                       Por defecto es \"\".\n",
    "    columns (list): Lista de columnas categóricas a considerar para pintar la distribución.\n",
    "                    Por defecto es la lista vacía.\n",
    "    mi_threshold (float): Umbral de mutual information. Por defecto es 0.0.\n",
    "    normalize (bool): Indica si se debe normalizar el valor de mutual information. Por defecto es False.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Comprobación de que el dataframe no esté vacío\n",
    "    if dataframe.empty:\n",
    "        print(\"Error: El dataframe está vacío.\")\n",
    "        return\n",
    "    \n",
    "    # Comprobación de que target_col exista en el dataframe\n",
    "    if target_col not in dataframe.columns:\n",
    "        print(f\"Error: La columna {target_col} no existe en el dataframe.\")\n",
    "        return\n",
    "\n",
    "    # Comprobación de que target_col sea categórica\n",
    "    if not pd.api.types.is_categorical_dtype(dataframe[target_col]):\n",
    "        print(f\"Error: La columna {target_col} no es categórica.\")\n",
    "        return\n",
    "    \n",
    "    # Comprobación de que mi_threshold sea un float válido entre 0 y 1 si normalize es True\n",
    "    if normalize and (not isinstance(mi_threshold, float) or mi_threshold < 0 or mi_threshold > 1):\n",
    "        print(\"Error: El valor de mi_threshold debe ser un float válido entre 0 y 1 cuando normalize es True.\")\n",
    "        return\n",
    "\n",
    "    # Filtrar columnas categóricas si columns está vacía\n",
    "    if not columns:\n",
    "        columns = dataframe.select_dtypes(include=['category']).columns.tolist()\n",
    "\n",
    "    # Comprobación de que hay al menos una columna categórica\n",
    "    if not columns:\n",
    "        print(\"Error: No hay columnas categóricas en el dataframe.\")\n",
    "        return\n",
    "\n",
    "    # Calcular mutual information\n",
    "    mi_values = mutual_info_classif(dataframe[columns], dataframe[target_col], discrete_features=True, random_state=42)\n",
    "    \n",
    "    # Normalizar si es necesario\n",
    "    if normalize:\n",
    "        total_mi = sum(mi_values)\n",
    "        mi_values = [mi / total_mi for mi in mi_values]\n",
    "    \n",
    "    # Seleccionar las columnas que cumplen con el threshold\n",
    "    selected_columns = [columns[i] for i, mi in enumerate(mi_values) if mi >= mi_threshold]\n",
    "\n",
    "    # Comprobación de que hay al menos una columna seleccionada\n",
    "    if not selected_columns:\n",
    "        print(\"Error: No hay columnas que cumplan con las condiciones de mutual information.\")\n",
    "        return\n",
    "\n",
    "    # Pintar la distribución de etiquetas para cada columna seleccionada\n",
    "    for col in selected_columns:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(x=col, hue=target_col, data=dataframe)\n",
    "        plt.title(f'Distribución de {col} respecto a {target_col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Conteo')\n",
    "        plt.legend(title=target_col)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
